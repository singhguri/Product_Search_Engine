https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/fighting-misinformation/ Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments How does YouTube address misinformation? With billions of people visiting us every day – whether they're looking to be informed, to catch up on the latest news or to learn more about the topics they care about, we have a responsibility to connect people to high-quality content. So the most important thing we can do is increase the good and decrease the bad. That's why we address misinformation on our platform based on our '4 Rs' principles: we remove content that violates our policies, reduce recommendations of borderline content, raise up authoritative sources for news and information and reward trusted creators. Learn more about how we treat misinformation on YouTube. Removing violative misinformation Misinformation policies Reducing the spread of borderline content Raising high-quality information Elevating quality information Providing context Rewarding trusted creators and artists Putting users in control Tools to flag content Media literacy What type of misinformation does YouTube remove? As detailed in our Community Guidelines, YouTube does not allow misleading or deceptive content that poses a serious risk of egregious harm. When it comes to misinformation, we need a clear set of facts to base our policies on. For example, for COVID-19 medical misinformation policies, we rely on expert consensus from both international health organisations and local health authorities. Our policies are developed in partnership with a wide range of external experts as well as YouTube Creators. We enforce our policies consistently using a combination of content reviewers and machine learning to remove content that violates our policies as quickly as possible. What types of misinformation are not allowed on YouTube? Several policies in our Community Guidelines are directly applicable to misinformation, for example: Misinformation policies These misinformation policies apply to certain types of misinformation that can cause egregious real-world harm such as promoting harmful remedies or treatments, certain types of technically manipulated content or content interfering with democratic processes such as census participation. Elections misinformation policies Our elections misinformation policies do not allow misleading or deceptive content with serious risk of egregious real-world harm like content containing hacked information which may interfere with democratic processes, false claims that could materially discourage voting or content with false claims related to candidate eligibility. COVID-19 medical misinformation policy The COVID-19 medical misinformation policy doesn't allow content that spreads medical misinformation which contradicts local and global health authorities' medical information about COVID-19. For example, we don't allow content that denies the existence of COVID-19 or promotes unapproved treatment or prevention methods. Vaccine misinformation policy The vaccine misinformation policy doesn't allow content that poses a serious risk of egregious harm by spreading medical misinformation about currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and by the World Health Organization (WHO). This is limited to content that contradicts local health authorities' or the WHO's guidance on vaccine safety, efficacy and ingredients. How does YouTube limit the spread of borderline content and potentially harmful misinformation? Sometimes, we see content that comes close to – but doesn't quite cross the line of – violating our Community Guidelines. We call this borderline content. Globally, consumption of borderline content or potentially harmful misinformation that comes from our recommendations is significantly below 1% of all consumption of content from recommendations. That said, even a fraction of a percent is too much. So, we do not proactively recommend such content on YouTube, thereby limiting its spread. We have careful systems in place to help us determine what is borderline content and potentially harmful misinformation across the wide variety of videos on YouTube. As part of this, we ask external evaluators and experts to provide critical input on the quality of a video. And these evaluators use public guidelines to guide their work. Based on the consensus input from the evaluators, we use well-tested machine learning systems to build models. These models help review hundreds of thousands of hours of videos every day in order to find and limit the spread of borderline content and potentially harmful misinformation. And over time, the accuracy of these systems will continue to improve. How does YouTube raise authoritative content? For topics such as news, politics, medical and scientific information, the quality of information is key. That's why we have continued to invest in our efforts to connect viewers with quality information and introduced a suite of features to elevate quality information from authoritative sources and provide context to help you make informed decisions. How does YouTube elevate quality information for viewers? For content where accuracy is key, including news, politics, medical and scientific information, we use machine learning systems that prioritise information from authoritative sources in search results and recommendations. To help you stay connected with the latest news, we highlight authoritative sources in news shelves that appear on the YouTube homepage during breaking news moments, as well as above YouTube search results to show top news when you are looking for news-related topics. News content shelves Resources Learn more about YouTube's news products How does YouTube determine what is an authoritative source? We use a number of signals to determine authoritativeness. External raters and experts are trained using public guidelines to provide critical input and guidance on the authoritativeness of videos. Additionally, we use input from Google Search and Google News such as the relevance and freshness of the content, as well as the expertise of the source, to determine the content you see in our officially labelled news surfaces. Resources Learn more about how Google News works How does YouTube provide more context to viewers to help them evaluate information? We highlight text-based information from authoritative third-party sources using information panels. As you navigate YouTube, you might see a variety of different information panels providing additional context, each of which is designed to help you make your own decisions about the content you find. For example, in developing news situations, when high quality video may not be immediately available, we display links to text-based news articles from authoritative sources in YouTube search results. Developing news information panel We display information panels above certain search results to highlight relevant fact checks from third-party fact-checking experts. Fact-check information panel For well-established historical, scientific and health topics that are often subject to misinformation, such as 'Apollo 11' or 'COVID-19 vaccine', you may see information panels alongside related search results and videos linking to independent third-party sources including Encyclopedia Britannica, the World Health Organization and locally relevant health officials. Topical information panel Since knowledge around funding sources can provide context when assessing an organisation's background and help you become a more informed viewer, we also show government or public funding for news publishers via information panels alongside their videos. Publisher funding information panel Information panels alongside health videos provide health source context and can help you better evaluate if a source is an accredited organisation or government health source. Information panel that provides health source context Resources Learn more about information panels How does YouTube encourage trustworthy creators? YouTube’s unique business model only works when our community believes that we are living up to our responsibility as a business. Not only does controversial content not perform well on YouTube, it also erodes trust with viewers, advertisers, and trusted creators themselves. All channels on YouTube must comply with our Community Guidelines. We set an even higher bar for creators to be eligible to make money on our platform via the YouTube Partner Program (YPP). In order to monetise, channels must also comply with the YouTube channel monetisation policies, which includes our Advertiser-friendly content guidelines which do not allow ads on content promoting or advocating for harmful health or medical claims; or content advocating for groups which promote harmful misinformation. Violation of our YouTube channel monetisation policies may result in monetisation being suspended. Creators can re-apply to join YPP after a certain time period. Putting users in control While YouTube addresses misinformation on our platform with policies and products based on the '4 Rs' principles, we also empower the YouTube community by giving users controls to flag misinformation and by investing in media literacy efforts. How can the broader community help flag misinformation on YouTube? YouTube removes content that violates our Community Guidelines, however, creators and viewers may still come across content that might need to be deleted or blocked. Anyone who is signed in can use our flagging features to submit content such as video, comment, playlist for review, if they think that it is inappropriate and in violation of our Community Guidelines. We also have tools and filters that allow creators to review or remove comments that they find offensive to themselves and their community. What are YouTube and Google doing to help people build media literacy skills? While YouTube tackles misinformation on the platform by applying the 4 Rs principles, we also want to support users in thinking critically about the content that they see on YouTube and the online world so that they can make their own informed decisions. We do this in three ways: help users' build media literacy skills; enable the work of organisations who work on media literacy initiatives; and invest in thought leadership to understand the broader context of misinformation. Helping users YouTube launched a media literacy programme to help adults and children better assess the accuracy of information so that they can confidently explore YouTube and beyond. The programme features practical media literacy tips for adults as well as children to help them spot misleading information. This programme is live in selected countries and we are working to expand to more countries. As parents play an important role in helping children learn the rules of the road, YouTube has also developed a family guide in partnership with National PTA and Parent Zone to cover media literacy tips and tools for parents to share with children. These efforts build on Google's continued commitment to support digital media literacy. In 2017, Google partnered with online safety and media literacy experts to create the 'Be Internet Awesome' programme to help educators and parents teach children the fundamentals of digital safety and citizenship. As a part of that curriculum, Google also launched a media literacy resource for teachers to help children understand persuasion and credibility in content they see online. Enabling organisations In 2021, Google contributed €25 million to help launch the European Media and Information Fund. The five-year commitment will support the work of the European University Institute, the Calouste Gulbenkian Foundation and the European Digital Media Observatory to fund organisations seeking to help adults and young people strengthen their media literacy skills. This five-year commitment is a continuation of Google's history of supporting and scaling the critical work of organisations focused on media literacy. In 2018, Google.org invested in supporting MediaWise, an initiative designed to help millions of teenagers in the US discern fact from fiction online. MediaWise is composed of industry leaders Poynter Institute, Stanford University, Local Media Association and the National Association for Media Literacy Education. Investing in thought leadership As the nature of misinformation rapidly evolves, it is critical that people understand the broader context of misinformation on the internet. Jigsaw, a unit within Google, has developed research, technology and thought leadership in collaboration with academics and journalists to explore how misinformation campaigns work and spread in today's open societies. Related articles Supporting political integrity Read more Community Guidelines Read more News and information Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/fighting-misinformation/#content Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments How does YouTube address misinformation? With billions of people visiting us every day – whether they're looking to be informed, to catch up on the latest news or to learn more about the topics they care about, we have a responsibility to connect people to high-quality content. So the most important thing we can do is increase the good and decrease the bad. That's why we address misinformation on our platform based on our '4 Rs' principles: we remove content that violates our policies, reduce recommendations of borderline content, raise up authoritative sources for news and information and reward trusted creators. Learn more about how we treat misinformation on YouTube. Removing violative misinformation Misinformation policies Reducing the spread of borderline content Raising high-quality information Elevating quality information Providing context Rewarding trusted creators and artists Putting users in control Tools to flag content Media literacy What type of misinformation does YouTube remove? As detailed in our Community Guidelines, YouTube does not allow misleading or deceptive content that poses a serious risk of egregious harm. When it comes to misinformation, we need a clear set of facts to base our policies on. For example, for COVID-19 medical misinformation policies, we rely on expert consensus from both international health organisations and local health authorities. Our policies are developed in partnership with a wide range of external experts as well as YouTube Creators. We enforce our policies consistently using a combination of content reviewers and machine learning to remove content that violates our policies as quickly as possible. What types of misinformation are not allowed on YouTube? Several policies in our Community Guidelines are directly applicable to misinformation, for example: Misinformation policies These misinformation policies apply to certain types of misinformation that can cause egregious real-world harm such as promoting harmful remedies or treatments, certain types of technically manipulated content or content interfering with democratic processes such as census participation. Elections misinformation policies Our elections misinformation policies do not allow misleading or deceptive content with serious risk of egregious real-world harm like content containing hacked information which may interfere with democratic processes, false claims that could materially discourage voting or content with false claims related to candidate eligibility. COVID-19 medical misinformation policy The COVID-19 medical misinformation policy doesn't allow content that spreads medical misinformation which contradicts local and global health authorities' medical information about COVID-19. For example, we don't allow content that denies the existence of COVID-19 or promotes unapproved treatment or prevention methods. Vaccine misinformation policy The vaccine misinformation policy doesn't allow content that poses a serious risk of egregious harm by spreading medical misinformation about currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and by the World Health Organization (WHO). This is limited to content that contradicts local health authorities' or the WHO's guidance on vaccine safety, efficacy and ingredients. How does YouTube limit the spread of borderline content and potentially harmful misinformation? Sometimes, we see content that comes close to – but doesn't quite cross the line of – violating our Community Guidelines. We call this borderline content. Globally, consumption of borderline content or potentially harmful misinformation that comes from our recommendations is significantly below 1% of all consumption of content from recommendations. That said, even a fraction of a percent is too much. So, we do not proactively recommend such content on YouTube, thereby limiting its spread. We have careful systems in place to help us determine what is borderline content and potentially harmful misinformation across the wide variety of videos on YouTube. As part of this, we ask external evaluators and experts to provide critical input on the quality of a video. And these evaluators use public guidelines to guide their work. Based on the consensus input from the evaluators, we use well-tested machine learning systems to build models. These models help review hundreds of thousands of hours of videos every day in order to find and limit the spread of borderline content and potentially harmful misinformation. And over time, the accuracy of these systems will continue to improve. How does YouTube raise authoritative content? For topics such as news, politics, medical and scientific information, the quality of information is key. That's why we have continued to invest in our efforts to connect viewers with quality information and introduced a suite of features to elevate quality information from authoritative sources and provide context to help you make informed decisions. How does YouTube elevate quality information for viewers? For content where accuracy is key, including news, politics, medical and scientific information, we use machine learning systems that prioritise information from authoritative sources in search results and recommendations. To help you stay connected with the latest news, we highlight authoritative sources in news shelves that appear on the YouTube homepage during breaking news moments, as well as above YouTube search results to show top news when you are looking for news-related topics. News content shelves Resources Learn more about YouTube's news products How does YouTube determine what is an authoritative source? We use a number of signals to determine authoritativeness. External raters and experts are trained using public guidelines to provide critical input and guidance on the authoritativeness of videos. Additionally, we use input from Google Search and Google News such as the relevance and freshness of the content, as well as the expertise of the source, to determine the content you see in our officially labelled news surfaces. Resources Learn more about how Google News works How does YouTube provide more context to viewers to help them evaluate information? We highlight text-based information from authoritative third-party sources using information panels. As you navigate YouTube, you might see a variety of different information panels providing additional context, each of which is designed to help you make your own decisions about the content you find. For example, in developing news situations, when high quality video may not be immediately available, we display links to text-based news articles from authoritative sources in YouTube search results. Developing news information panel We display information panels above certain search results to highlight relevant fact checks from third-party fact-checking experts. Fact-check information panel For well-established historical, scientific and health topics that are often subject to misinformation, such as 'Apollo 11' or 'COVID-19 vaccine', you may see information panels alongside related search results and videos linking to independent third-party sources including Encyclopedia Britannica, the World Health Organization and locally relevant health officials. Topical information panel Since knowledge around funding sources can provide context when assessing an organisation's background and help you become a more informed viewer, we also show government or public funding for news publishers via information panels alongside their videos. Publisher funding information panel Information panels alongside health videos provide health source context and can help you better evaluate if a source is an accredited organisation or government health source. Information panel that provides health source context Resources Learn more about information panels How does YouTube encourage trustworthy creators? YouTube’s unique business model only works when our community believes that we are living up to our responsibility as a business. Not only does controversial content not perform well on YouTube, it also erodes trust with viewers, advertisers, and trusted creators themselves. All channels on YouTube must comply with our Community Guidelines. We set an even higher bar for creators to be eligible to make money on our platform via the YouTube Partner Program (YPP). In order to monetise, channels must also comply with the YouTube channel monetisation policies, which includes our Advertiser-friendly content guidelines which do not allow ads on content promoting or advocating for harmful health or medical claims; or content advocating for groups which promote harmful misinformation. Violation of our YouTube channel monetisation policies may result in monetisation being suspended. Creators can re-apply to join YPP after a certain time period. Putting users in control While YouTube addresses misinformation on our platform with policies and products based on the '4 Rs' principles, we also empower the YouTube community by giving users controls to flag misinformation and by investing in media literacy efforts. How can the broader community help flag misinformation on YouTube? YouTube removes content that violates our Community Guidelines, however, creators and viewers may still come across content that might need to be deleted or blocked. Anyone who is signed in can use our flagging features to submit content such as video, comment, playlist for review, if they think that it is inappropriate and in violation of our Community Guidelines. We also have tools and filters that allow creators to review or remove comments that they find offensive to themselves and their community. What are YouTube and Google doing to help people build media literacy skills? While YouTube tackles misinformation on the platform by applying the 4 Rs principles, we also want to support users in thinking critically about the content that they see on YouTube and the online world so that they can make their own informed decisions. We do this in three ways: help users' build media literacy skills; enable the work of organisations who work on media literacy initiatives; and invest in thought leadership to understand the broader context of misinformation. Helping users YouTube launched a media literacy programme to help adults and children better assess the accuracy of information so that they can confidently explore YouTube and beyond. The programme features practical media literacy tips for adults as well as children to help them spot misleading information. This programme is live in selected countries and we are working to expand to more countries. As parents play an important role in helping children learn the rules of the road, YouTube has also developed a family guide in partnership with National PTA and Parent Zone to cover media literacy tips and tools for parents to share with children. These efforts build on Google's continued commitment to support digital media literacy. In 2017, Google partnered with online safety and media literacy experts to create the 'Be Internet Awesome' programme to help educators and parents teach children the fundamentals of digital safety and citizenship. As a part of that curriculum, Google also launched a media literacy resource for teachers to help children understand persuasion and credibility in content they see online. Enabling organisations In 2021, Google contributed €25 million to help launch the European Media and Information Fund. The five-year commitment will support the work of the European University Institute, the Calouste Gulbenkian Foundation and the European Digital Media Observatory to fund organisations seeking to help adults and young people strengthen their media literacy skills. This five-year commitment is a continuation of Google's history of supporting and scaling the critical work of organisations focused on media literacy. In 2018, Google.org invested in supporting MediaWise, an initiative designed to help millions of teenagers in the US discern fact from fiction online. MediaWise is composed of industry leaders Poynter Institute, Stanford University, Local Media Association and the National Association for Media Literacy Education. Investing in thought leadership As the nature of misinformation rapidly evolves, it is critical that people understand the broader context of misinformation on the internet. Jigsaw, a unit within Google, has developed research, technology and thought leadership in collaboration with academics and journalists to explore how misinformation campaigns work and spread in today's open societies. Related articles Supporting political integrity Read more Community Guidelines Read more News and information Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/fighting-misinformation/ Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments How does YouTube address misinformation? With billions of people visiting us every day – whether they're looking to be informed, to catch up on the latest news or to learn more about the topics they care about, we have a responsibility to connect people to high-quality content. So the most important thing we can do is increase the good and decrease the bad. That's why we address misinformation on our platform based on our '4 Rs' principles: we remove content that violates our policies, reduce recommendations of borderline content, raise up authoritative sources for news and information and reward trusted creators. Learn more about how we treat misinformation on YouTube. Removing violative misinformation Misinformation policies Reducing the spread of borderline content Raising high-quality information Elevating quality information Providing context Rewarding trusted creators and artists Putting users in control Tools to flag content Media literacy What type of misinformation does YouTube remove? As detailed in our Community Guidelines, YouTube does not allow misleading or deceptive content that poses a serious risk of egregious harm. When it comes to misinformation, we need a clear set of facts to base our policies on. For example, for COVID-19 medical misinformation policies, we rely on expert consensus from both international health organisations and local health authorities. Our policies are developed in partnership with a wide range of external experts as well as YouTube Creators. We enforce our policies consistently using a combination of content reviewers and machine learning to remove content that violates our policies as quickly as possible. What types of misinformation are not allowed on YouTube? Several policies in our Community Guidelines are directly applicable to misinformation, for example: Misinformation policies These misinformation policies apply to certain types of misinformation that can cause egregious real-world harm such as promoting harmful remedies or treatments, certain types of technically manipulated content or content interfering with democratic processes such as census participation. Elections misinformation policies Our elections misinformation policies do not allow misleading or deceptive content with serious risk of egregious real-world harm like content containing hacked information which may interfere with democratic processes, false claims that could materially discourage voting or content with false claims related to candidate eligibility. COVID-19 medical misinformation policy The COVID-19 medical misinformation policy doesn't allow content that spreads medical misinformation which contradicts local and global health authorities' medical information about COVID-19. For example, we don't allow content that denies the existence of COVID-19 or promotes unapproved treatment or prevention methods. Vaccine misinformation policy The vaccine misinformation policy doesn't allow content that poses a serious risk of egregious harm by spreading medical misinformation about currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and by the World Health Organization (WHO). This is limited to content that contradicts local health authorities' or the WHO's guidance on vaccine safety, efficacy and ingredients. How does YouTube limit the spread of borderline content and potentially harmful misinformation? Sometimes, we see content that comes close to – but doesn't quite cross the line of – violating our Community Guidelines. We call this borderline content. Globally, consumption of borderline content or potentially harmful misinformation that comes from our recommendations is significantly below 1% of all consumption of content from recommendations. That said, even a fraction of a percent is too much. So, we do not proactively recommend such content on YouTube, thereby limiting its spread. We have careful systems in place to help us determine what is borderline content and potentially harmful misinformation across the wide variety of videos on YouTube. As part of this, we ask external evaluators and experts to provide critical input on the quality of a video. And these evaluators use public guidelines to guide their work. Based on the consensus input from the evaluators, we use well-tested machine learning systems to build models. These models help review hundreds of thousands of hours of videos every day in order to find and limit the spread of borderline content and potentially harmful misinformation. And over time, the accuracy of these systems will continue to improve. How does YouTube raise authoritative content? For topics such as news, politics, medical and scientific information, the quality of information is key. That's why we have continued to invest in our efforts to connect viewers with quality information and introduced a suite of features to elevate quality information from authoritative sources and provide context to help you make informed decisions. How does YouTube elevate quality information for viewers? For content where accuracy is key, including news, politics, medical and scientific information, we use machine learning systems that prioritise information from authoritative sources in search results and recommendations. To help you stay connected with the latest news, we highlight authoritative sources in news shelves that appear on the YouTube homepage during breaking news moments, as well as above YouTube search results to show top news when you are looking for news-related topics. News content shelves Resources Learn more about YouTube's news products How does YouTube determine what is an authoritative source? We use a number of signals to determine authoritativeness. External raters and experts are trained using public guidelines to provide critical input and guidance on the authoritativeness of videos. Additionally, we use input from Google Search and Google News such as the relevance and freshness of the content, as well as the expertise of the source, to determine the content you see in our officially labelled news surfaces. Resources Learn more about how Google News works How does YouTube provide more context to viewers to help them evaluate information? We highlight text-based information from authoritative third-party sources using information panels. As you navigate YouTube, you might see a variety of different information panels providing additional context, each of which is designed to help you make your own decisions about the content you find. For example, in developing news situations, when high quality video may not be immediately available, we display links to text-based news articles from authoritative sources in YouTube search results. Developing news information panel We display information panels above certain search results to highlight relevant fact checks from third-party fact-checking experts. Fact-check information panel For well-established historical, scientific and health topics that are often subject to misinformation, such as 'Apollo 11' or 'COVID-19 vaccine', you may see information panels alongside related search results and videos linking to independent third-party sources including Encyclopedia Britannica, the World Health Organization and locally relevant health officials. Topical information panel Since knowledge around funding sources can provide context when assessing an organisation's background and help you become a more informed viewer, we also show government or public funding for news publishers via information panels alongside their videos. Publisher funding information panel Information panels alongside health videos provide health source context and can help you better evaluate if a source is an accredited organisation or government health source. Information panel that provides health source context Resources Learn more about information panels How does YouTube encourage trustworthy creators? YouTube’s unique business model only works when our community believes that we are living up to our responsibility as a business. Not only does controversial content not perform well on YouTube, it also erodes trust with viewers, advertisers, and trusted creators themselves. All channels on YouTube must comply with our Community Guidelines. We set an even higher bar for creators to be eligible to make money on our platform via the YouTube Partner Program (YPP). In order to monetise, channels must also comply with the YouTube channel monetisation policies, which includes our Advertiser-friendly content guidelines which do not allow ads on content promoting or advocating for harmful health or medical claims; or content advocating for groups which promote harmful misinformation. Violation of our YouTube channel monetisation policies may result in monetisation being suspended. Creators can re-apply to join YPP after a certain time period. Putting users in control While YouTube addresses misinformation on our platform with policies and products based on the '4 Rs' principles, we also empower the YouTube community by giving users controls to flag misinformation and by investing in media literacy efforts. How can the broader community help flag misinformation on YouTube? YouTube removes content that violates our Community Guidelines, however, creators and viewers may still come across content that might need to be deleted or blocked. Anyone who is signed in can use our flagging features to submit content such as video, comment, playlist for review, if they think that it is inappropriate and in violation of our Community Guidelines. We also have tools and filters that allow creators to review or remove comments that they find offensive to themselves and their community. What are YouTube and Google doing to help people build media literacy skills? While YouTube tackles misinformation on the platform by applying the 4 Rs principles, we also want to support users in thinking critically about the content that they see on YouTube and the online world so that they can make their own informed decisions. We do this in three ways: help users' build media literacy skills; enable the work of organisations who work on media literacy initiatives; and invest in thought leadership to understand the broader context of misinformation. Helping users YouTube launched a media literacy programme to help adults and children better assess the accuracy of information so that they can confidently explore YouTube and beyond. The programme features practical media literacy tips for adults as well as children to help them spot misleading information. This programme is live in selected countries and we are working to expand to more countries. As parents play an important role in helping children learn the rules of the road, YouTube has also developed a family guide in partnership with National PTA and Parent Zone to cover media literacy tips and tools for parents to share with children. These efforts build on Google's continued commitment to support digital media literacy. In 2017, Google partnered with online safety and media literacy experts to create the 'Be Internet Awesome' programme to help educators and parents teach children the fundamentals of digital safety and citizenship. As a part of that curriculum, Google also launched a media literacy resource for teachers to help children understand persuasion and credibility in content they see online. Enabling organisations In 2021, Google contributed €25 million to help launch the European Media and Information Fund. The five-year commitment will support the work of the European University Institute, the Calouste Gulbenkian Foundation and the European Digital Media Observatory to fund organisations seeking to help adults and young people strengthen their media literacy skills. This five-year commitment is a continuation of Google's history of supporting and scaling the critical work of organisations focused on media literacy. In 2018, Google.org invested in supporting MediaWise, an initiative designed to help millions of teenagers in the US discern fact from fiction online. MediaWise is composed of industry leaders Poynter Institute, Stanford University, Local Media Association and the National Association for Media Literacy Education. Investing in thought leadership As the nature of misinformation rapidly evolves, it is critical that people understand the broader context of misinformation on the internet. Jigsaw, a unit within Google, has developed research, technology and thought leadership in collaboration with academics and journalists to explore how misinformation campaigns work and spread in today's open societies. Related articles Supporting political integrity Read more Community Guidelines Read more News and information Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/fighting-misinformation/#content Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments How does YouTube address misinformation? With billions of people visiting us every day – whether they're looking to be informed, to catch up on the latest news or to learn more about the topics they care about, we have a responsibility to connect people to high-quality content. So the most important thing we can do is increase the good and decrease the bad. That's why we address misinformation on our platform based on our '4 Rs' principles: we remove content that violates our policies, reduce recommendations of borderline content, raise up authoritative sources for news and information and reward trusted creators. Learn more about how we treat misinformation on YouTube. Removing violative misinformation Misinformation policies Reducing the spread of borderline content Raising high-quality information Elevating quality information Providing context Rewarding trusted creators and artists Putting users in control Tools to flag content Media literacy What type of misinformation does YouTube remove? As detailed in our Community Guidelines, YouTube does not allow misleading or deceptive content that poses a serious risk of egregious harm. When it comes to misinformation, we need a clear set of facts to base our policies on. For example, for COVID-19 medical misinformation policies, we rely on expert consensus from both international health organisations and local health authorities. Our policies are developed in partnership with a wide range of external experts as well as YouTube Creators. We enforce our policies consistently using a combination of content reviewers and machine learning to remove content that violates our policies as quickly as possible. What types of misinformation are not allowed on YouTube? Several policies in our Community Guidelines are directly applicable to misinformation, for example: Misinformation policies These misinformation policies apply to certain types of misinformation that can cause egregious real-world harm such as promoting harmful remedies or treatments, certain types of technically manipulated content or content interfering with democratic processes such as census participation. Elections misinformation policies Our elections misinformation policies do not allow misleading or deceptive content with serious risk of egregious real-world harm like content containing hacked information which may interfere with democratic processes, false claims that could materially discourage voting or content with false claims related to candidate eligibility. COVID-19 medical misinformation policy The COVID-19 medical misinformation policy doesn't allow content that spreads medical misinformation which contradicts local and global health authorities' medical information about COVID-19. For example, we don't allow content that denies the existence of COVID-19 or promotes unapproved treatment or prevention methods. Vaccine misinformation policy The vaccine misinformation policy doesn't allow content that poses a serious risk of egregious harm by spreading medical misinformation about currently administered vaccines that are approved and confirmed to be safe and effective by local health authorities and by the World Health Organization (WHO). This is limited to content that contradicts local health authorities' or the WHO's guidance on vaccine safety, efficacy and ingredients. How does YouTube limit the spread of borderline content and potentially harmful misinformation? Sometimes, we see content that comes close to – but doesn't quite cross the line of – violating our Community Guidelines. We call this borderline content. Globally, consumption of borderline content or potentially harmful misinformation that comes from our recommendations is significantly below 1% of all consumption of content from recommendations. That said, even a fraction of a percent is too much. So, we do not proactively recommend such content on YouTube, thereby limiting its spread. We have careful systems in place to help us determine what is borderline content and potentially harmful misinformation across the wide variety of videos on YouTube. As part of this, we ask external evaluators and experts to provide critical input on the quality of a video. And these evaluators use public guidelines to guide their work. Based on the consensus input from the evaluators, we use well-tested machine learning systems to build models. These models help review hundreds of thousands of hours of videos every day in order to find and limit the spread of borderline content and potentially harmful misinformation. And over time, the accuracy of these systems will continue to improve. How does YouTube raise authoritative content? For topics such as news, politics, medical and scientific information, the quality of information is key. That's why we have continued to invest in our efforts to connect viewers with quality information and introduced a suite of features to elevate quality information from authoritative sources and provide context to help you make informed decisions. How does YouTube elevate quality information for viewers? For content where accuracy is key, including news, politics, medical and scientific information, we use machine learning systems that prioritise information from authoritative sources in search results and recommendations. To help you stay connected with the latest news, we highlight authoritative sources in news shelves that appear on the YouTube homepage during breaking news moments, as well as above YouTube search results to show top news when you are looking for news-related topics. News content shelves Resources Learn more about YouTube's news products How does YouTube determine what is an authoritative source? We use a number of signals to determine authoritativeness. External raters and experts are trained using public guidelines to provide critical input and guidance on the authoritativeness of videos. Additionally, we use input from Google Search and Google News such as the relevance and freshness of the content, as well as the expertise of the source, to determine the content you see in our officially labelled news surfaces. Resources Learn more about how Google News works How does YouTube provide more context to viewers to help them evaluate information? We highlight text-based information from authoritative third-party sources using information panels. As you navigate YouTube, you might see a variety of different information panels providing additional context, each of which is designed to help you make your own decisions about the content you find. For example, in developing news situations, when high quality video may not be immediately available, we display links to text-based news articles from authoritative sources in YouTube search results. Developing news information panel We display information panels above certain search results to highlight relevant fact checks from third-party fact-checking experts. Fact-check information panel For well-established historical, scientific and health topics that are often subject to misinformation, such as 'Apollo 11' or 'COVID-19 vaccine', you may see information panels alongside related search results and videos linking to independent third-party sources including Encyclopedia Britannica, the World Health Organization and locally relevant health officials. Topical information panel Since knowledge around funding sources can provide context when assessing an organisation's background and help you become a more informed viewer, we also show government or public funding for news publishers via information panels alongside their videos. Publisher funding information panel Information panels alongside health videos provide health source context and can help you better evaluate if a source is an accredited organisation or government health source. Information panel that provides health source context Resources Learn more about information panels How does YouTube encourage trustworthy creators? YouTube’s unique business model only works when our community believes that we are living up to our responsibility as a business. Not only does controversial content not perform well on YouTube, it also erodes trust with viewers, advertisers, and trusted creators themselves. All channels on YouTube must comply with our Community Guidelines. We set an even higher bar for creators to be eligible to make money on our platform via the YouTube Partner Program (YPP). In order to monetise, channels must also comply with the YouTube channel monetisation policies, which includes our Advertiser-friendly content guidelines which do not allow ads on content promoting or advocating for harmful health or medical claims; or content advocating for groups which promote harmful misinformation. Violation of our YouTube channel monetisation policies may result in monetisation being suspended. Creators can re-apply to join YPP after a certain time period. Putting users in control While YouTube addresses misinformation on our platform with policies and products based on the '4 Rs' principles, we also empower the YouTube community by giving users controls to flag misinformation and by investing in media literacy efforts. How can the broader community help flag misinformation on YouTube? YouTube removes content that violates our Community Guidelines, however, creators and viewers may still come across content that might need to be deleted or blocked. Anyone who is signed in can use our flagging features to submit content such as video, comment, playlist for review, if they think that it is inappropriate and in violation of our Community Guidelines. We also have tools and filters that allow creators to review or remove comments that they find offensive to themselves and their community. What are YouTube and Google doing to help people build media literacy skills? While YouTube tackles misinformation on the platform by applying the 4 Rs principles, we also want to support users in thinking critically about the content that they see on YouTube and the online world so that they can make their own informed decisions. We do this in three ways: help users' build media literacy skills; enable the work of organisations who work on media literacy initiatives; and invest in thought leadership to understand the broader context of misinformation. Helping users YouTube launched a media literacy programme to help adults and children better assess the accuracy of information so that they can confidently explore YouTube and beyond. The programme features practical media literacy tips for adults as well as children to help them spot misleading information. This programme is live in selected countries and we are working to expand to more countries. As parents play an important role in helping children learn the rules of the road, YouTube has also developed a family guide in partnership with National PTA and Parent Zone to cover media literacy tips and tools for parents to share with children. These efforts build on Google's continued commitment to support digital media literacy. In 2017, Google partnered with online safety and media literacy experts to create the 'Be Internet Awesome' programme to help educators and parents teach children the fundamentals of digital safety and citizenship. As a part of that curriculum, Google also launched a media literacy resource for teachers to help children understand persuasion and credibility in content they see online. Enabling organisations In 2021, Google contributed €25 million to help launch the European Media and Information Fund. The five-year commitment will support the work of the European University Institute, the Calouste Gulbenkian Foundation and the European Digital Media Observatory to fund organisations seeking to help adults and young people strengthen their media literacy skills. This five-year commitment is a continuation of Google's history of supporting and scaling the critical work of organisations focused on media literacy. In 2018, Google.org invested in supporting MediaWise, an initiative designed to help millions of teenagers in the US discern fact from fiction online. MediaWise is composed of industry leaders Poynter Institute, Stanford University, Local Media Association and the National Association for Media Literacy Education. Investing in thought leadership As the nature of misinformation rapidly evolves, it is critical that people understand the broader context of misinformation on the internet. Jigsaw, a unit within Google, has developed research, technology and thought leadership in collaboration with academics and journalists to explore how misinformation campaigns work and spread in today's open societies. Related articles Supporting political integrity Read more Community Guidelines Read more News and information Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)