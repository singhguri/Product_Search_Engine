https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/curbing-extremist-content/ Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments Does YouTube contribute to radicalisation? We work hard to protect users from extremist content. We address extremist content by removing videos that violate our hate speech policy and violent criminal organisations policy. Our recommendation systems significantly limit the reach of borderline content and harmful misinformation that brushes up against the policy line but does not cross it. Policies Curbing borderline content Tackling violence What policies address extremist content? Any content designed to incite violence or hatred towards certain groups of people is against our hate speech policy. Additionally, content promoting or glorifying terrorism is against our violent criminal organisations policy. We remove this content when flagged to us. How does YouTube deal with content that does not violate policies but could still be considered harmful? Sometimes, there is content that brushes up against the policy line but does not cross it. We call this borderline content. Our recommendations systems help limit the spread of borderline content, and because of this, we've seen more than a 70% drop in watch time of this content coming from non-subscribed recommendations in the US. What is YouTube doing to specifically tackle content that promotes violent extremism and terrorism? Content promoting or glorifying terrorist and other violent criminal organisations does not have a home on YouTube. YouTube has automated systems that aid in the detection of content that may violate our policies, including our violent criminal organisations policy. Once potentially problematic content has been identified, human review verifies whether it violates our policies. If it does, the content is removed and is used to train our machines for better coverage in the future. Machine learning now helps us take down extremist content before it has been widely viewed. Between October and December 2019, approximately 90% of the videos uploaded that were removed for violating our violent extremism policy were taken down before they had 10 views. The YouTube community also helps us to spot this content. We have a designated 'promotes terrorism' flag underneath every video on YouTube that users can select when they report content. We also work with violent extremism experts through our Trusted Flagger programme. Teams carefully evaluate flags 24 hours a day, seven days a week. We are also a founding member of the Global Internet Forum to Counter Terrorism (GIFCT), where we work with other tech companies to keep terrorist content off the web while providing training and other resources to smaller companies facing similar challenges. Resources Learn more about our violent criminal organisations policy Learn more about how we enforce our violent extremism policy in our quarterly YouTube Community Guidelines enforcement report Related articles Standing up to hate Read more Managing harmful content Read more Recommended videos Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/curbing-extremist-content/#content Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments Does YouTube contribute to radicalisation? We work hard to protect users from extremist content. We address extremist content by removing videos that violate our hate speech policy and violent criminal organisations policy. Our recommendation systems significantly limit the reach of borderline content and harmful misinformation that brushes up against the policy line but does not cross it. Policies Curbing borderline content Tackling violence What policies address extremist content? Any content designed to incite violence or hatred towards certain groups of people is against our hate speech policy. Additionally, content promoting or glorifying terrorism is against our violent criminal organisations policy. We remove this content when flagged to us. How does YouTube deal with content that does not violate policies but could still be considered harmful? Sometimes, there is content that brushes up against the policy line but does not cross it. We call this borderline content. Our recommendations systems help limit the spread of borderline content, and because of this, we've seen more than a 70% drop in watch time of this content coming from non-subscribed recommendations in the US. What is YouTube doing to specifically tackle content that promotes violent extremism and terrorism? Content promoting or glorifying terrorist and other violent criminal organisations does not have a home on YouTube. YouTube has automated systems that aid in the detection of content that may violate our policies, including our violent criminal organisations policy. Once potentially problematic content has been identified, human review verifies whether it violates our policies. If it does, the content is removed and is used to train our machines for better coverage in the future. Machine learning now helps us take down extremist content before it has been widely viewed. Between October and December 2019, approximately 90% of the videos uploaded that were removed for violating our violent extremism policy were taken down before they had 10 views. The YouTube community also helps us to spot this content. We have a designated 'promotes terrorism' flag underneath every video on YouTube that users can select when they report content. We also work with violent extremism experts through our Trusted Flagger programme. Teams carefully evaluate flags 24 hours a day, seven days a week. We are also a founding member of the Global Internet Forum to Counter Terrorism (GIFCT), where we work with other tech companies to keep terrorist content off the web while providing training and other resources to smaller companies facing similar challenges. Resources Learn more about our violent criminal organisations policy Learn more about how we enforce our violent extremism policy in our quarterly YouTube Community Guidelines enforcement report Related articles Standing up to hate Read more Managing harmful content Read more Recommended videos Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/curbing-extremist-content/ Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments Does YouTube contribute to radicalisation? We work hard to protect users from extremist content. We address extremist content by removing videos that violate our hate speech policy and violent criminal organisations policy. Our recommendation systems significantly limit the reach of borderline content and harmful misinformation that brushes up against the policy line but does not cross it. Policies Curbing borderline content Tackling violence What policies address extremist content? Any content designed to incite violence or hatred towards certain groups of people is against our hate speech policy. Additionally, content promoting or glorifying terrorism is against our violent criminal organisations policy. We remove this content when flagged to us. How does YouTube deal with content that does not violate policies but could still be considered harmful? Sometimes, there is content that brushes up against the policy line but does not cross it. We call this borderline content. Our recommendations systems help limit the spread of borderline content, and because of this, we've seen more than a 70% drop in watch time of this content coming from non-subscribed recommendations in the US. What is YouTube doing to specifically tackle content that promotes violent extremism and terrorism? Content promoting or glorifying terrorist and other violent criminal organisations does not have a home on YouTube. YouTube has automated systems that aid in the detection of content that may violate our policies, including our violent criminal organisations policy. Once potentially problematic content has been identified, human review verifies whether it violates our policies. If it does, the content is removed and is used to train our machines for better coverage in the future. Machine learning now helps us take down extremist content before it has been widely viewed. Between October and December 2019, approximately 90% of the videos uploaded that were removed for violating our violent extremism policy were taken down before they had 10 views. The YouTube community also helps us to spot this content. We have a designated 'promotes terrorism' flag underneath every video on YouTube that users can select when they report content. We also work with violent extremism experts through our Trusted Flagger programme. Teams carefully evaluate flags 24 hours a day, seven days a week. We are also a founding member of the Global Internet Forum to Counter Terrorism (GIFCT), where we work with other tech companies to keep terrorist content off the web while providing training and other resources to smaller companies facing similar challenges. Resources Learn more about our violent criminal organisations policy Learn more about how we enforce our violent extremism policy in our quarterly YouTube Community Guidelines enforcement report Related articles Standing up to hate Read more Managing harmful content Read more Recommended videos Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)https://www.youtube.com/intl/ALL_ca/howyoutubeworks/our-commitments/curbing-extremist-content/#content Jump to content Our commitments Managing harmful content How does YouTube manage harmful content? Standing up to hate How does YouTube protect the community from hate and harassment? Fighting misinformation How does YouTube combat misinformation? Curbing extremist content How does YouTube prevent radicalisation? Supporting political integrity How does YouTube support civic engagement and election integrity? Partnering with Researchers How does YouTube partner with researchers? Preventing bias What does YouTube do to prevent bias? Fostering child safety How does YouTube help keep children protected on the platform? Protecting user data How does YouTube maintain user privacy? Safeguarding copyright How does YouTube protect copyrighted content? Sharing revenue How does YouTube make money? Promoting digital wellbeing How does YouTube support users' digital wellbeing? Responding to COVID-19 How is YouTube supporting users during COVID-19? Product features YouTube Search How our search tool can help you find content that you'll love Recommended videos How we recommend content that we think you'll want to watch News and information How we provide context for your search results and videos Monetisation for creators How creators earn money on YouTube YouTube Live How you can reach your community in real time with Live and Premieres User settings Privacy controls How we protect your information and what you can do to control your privacy Ad Settings How our advertising works and how to customise your ad experience Parental controls How you can create a family-friendly experience Auto-play How auto-play works and how to turn it off Rules and policies Policies overview How our rules and policies help keep our platform safe Community Guidelines How we define what we do and don't allow on YouTube Copyright How we help creators responsibly manage their content Monetisation policies How creators can monetise their content as part of the YouTube Partner Programme Legal removals How we approach content that violates local law Progress and impact Progress on managing harmful content How we're enforcing our policies on harmful content by the numbers Our impact How creative entrepreneurs are transforming their lives and communities Culture and trends How to better understand the next generation of creators and artists Resources Our commitments Does YouTube contribute to radicalisation? We work hard to protect users from extremist content. We address extremist content by removing videos that violate our hate speech policy and violent criminal organisations policy. Our recommendation systems significantly limit the reach of borderline content and harmful misinformation that brushes up against the policy line but does not cross it. Policies Curbing borderline content Tackling violence What policies address extremist content? Any content designed to incite violence or hatred towards certain groups of people is against our hate speech policy. Additionally, content promoting or glorifying terrorism is against our violent criminal organisations policy. We remove this content when flagged to us. How does YouTube deal with content that does not violate policies but could still be considered harmful? Sometimes, there is content that brushes up against the policy line but does not cross it. We call this borderline content. Our recommendations systems help limit the spread of borderline content, and because of this, we've seen more than a 70% drop in watch time of this content coming from non-subscribed recommendations in the US. What is YouTube doing to specifically tackle content that promotes violent extremism and terrorism? Content promoting or glorifying terrorist and other violent criminal organisations does not have a home on YouTube. YouTube has automated systems that aid in the detection of content that may violate our policies, including our violent criminal organisations policy. Once potentially problematic content has been identified, human review verifies whether it violates our policies. If it does, the content is removed and is used to train our machines for better coverage in the future. Machine learning now helps us take down extremist content before it has been widely viewed. Between October and December 2019, approximately 90% of the videos uploaded that were removed for violating our violent extremism policy were taken down before they had 10 views. The YouTube community also helps us to spot this content. We have a designated 'promotes terrorism' flag underneath every video on YouTube that users can select when they report content. We also work with violent extremism experts through our Trusted Flagger programme. Teams carefully evaluate flags 24 hours a day, seven days a week. We are also a founding member of the Global Internet Forum to Counter Terrorism (GIFCT), where we work with other tech companies to keep terrorist content off the web while providing training and other resources to smaller companies facing similar challenges. Resources Learn more about our violent criminal organisations policy Learn more about how we enforce our violent extremism policy in our quarterly YouTube Community Guidelines enforcement report Related articles Standing up to hate Read more Managing harmful content Read more Recommended videos Read more Connect About YouTube About Blog How YouTube Works Jobs Press YouTube Culture & Trends Products YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV For Business Developers YouTube Advertising For Creators Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Our Commitments Creators for Change CSAI Match Social impact About YouTube Products For Business For Creators Our Commitments About Blog How YouTube Works Jobs Press YouTube Culture & Trends YouTube Kids YouTube Music YouTube Originals YouTube Premium YouTube Select YouTube Studio YouTube TV Developers YouTube Advertising Creating for YouTube Kids Creator Research Creator Services Directory YouTube Artists YouTube Creators YouTube NextUp YouTube VR Creators for Change CSAI Match Social impact Policies & safety Copyright Brand guidelines Privacy Terms Help English Deutsch (Österreich) English (Australia) Nederlands (België) български (България) português (Brasil) English (Canada) čeština (Česko) Deutsch (Deutschland) dansk (Danmark) eesti (Eesti) español (España) suomi (Suomi) français (France) Ελληνικά (Ελλάδα) hrvatski (Hrvatska) magyar (Magyarország) Bahasa Indonesia (Bahasa Indonesia) English (Ireland) English (India) italiano (Italia) 日本語 (日本) 한국어 (대한민국) lietuvių (Lietuva) Deutsch (Luxemburg) latviešu (Latvija) Nederlands (Nederland) polski (Polska) português (Portugal) română (România) русский (Россия) svenska (Sverige) slovenščina (Slovenija) slovenčina (Slovensko) Türkçe (Türkiye) English (United Kingdom) Tiếng Việt (Việt Nam) العربية Deutsch (Belgien) Ελληνικά (Κύπρος) English (Belgium) English (Malta) español (Estados Unidos) français (Belgique) français (Canada) français (Luxembourg) हिन्दी (भारत) עברית (ישראל) Kiswahili Türkçe (Kıbrıs) 中文 (繁體)